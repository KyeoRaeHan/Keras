## 분류 모델



#### 로지스틱 회귀(Logistic Regression)

선형적으로 구분되는 데이터에서 뛰어난 성능을 내는 모델.

이진분류, 다중분류에서 전부 사용.



#### 서포트 벡터 머신(SVM, Support Vector Machine)

**SVM**은 굉장히 높은 정확도를 보이며, 주로 다루려는 데이터를 2개의 그룹으로 분류할 때 많이 사용하는 분류기법 중 최상의 기법이다.



**SVM**은 무작정 Margin을 크게 하는 구분선을 택하는 것이 아니라,

우선, 데이터를 정확히 분류하는 범위를 먼저 찾고, 그 범위 안에서 Margin을 최대화하는 구분선을 선택한다. 

Margin을 최대화하는 이유는 일반화 오차가 낮아지는 경향이 있기 때문이다.



**용어**

###### Margin(마진)

클래스를 구분하는 초평면(결정경계)과 이 초평면에 가장 가까운 훈련 샘플 사이의 거리

(구분하는 선과 서포트 벡터와의 거리를 의미)

###### Decision Boundary(결정경계)

두 데이터를 구분하는 선

###### Support vector(서포트벡터)

선과 가장 가까운 포인트



#### 결정트리(Decision Tree)
분류와 회귀 모두 가능한 지도학습 모델. 특정 기준(질문)에 따라 데이터를 구분한다.

![tree](https://user-images.githubusercontent.com/59241047/75026937-1da5c780-54e1-11ea-8c69-527c71a38699.PNG)


#### 프로세스
![tree2](https://user-images.githubusercontent.com/59241047/75026996-344c1e80-54e1-11ea-9bc6-ca7a7d30f382.PNG)



### 가지치기(Pruning): 오버피팅을 막기 위한 전략

트리에 가지가 너무 많다면 과대적합(overfitting)이 일어난다. 그래서  최대 깊이나 터미널 노드의 최대 개수, 혹은 한 노드가 분할하기 위한 최소 데이터 수를 제한하는 가지치기 기법을 사용한다.

**min_sample_split** 

한 노드에 들어있는 최소 데이터 수를 정해줄 수 있습니다.

(ex- min_sample_split = 10이면 한 노드에 10개의 데이터가 있다면 그 노드는 더 이상 분기를 하지 않습니다. )

**max_depth**

최대 깊이를 지정해줄 수도 있습니다. 

(max_depth = 4이면, 깊이가 4보다 크게 가지를 치지 않습니다. )



가지치기는 사전 가지치기와 사후 가지치기가 있지만 sklearn에서는 사전 가지치기만 지원합니다.



### 알고리즘: 엔트로피(Entropy), 불순도(Impurity)

엔트로피(Entropy)는 불순도(Impurity)를 수치적으로 나타낸 척도.

엔트로피가 높다는 것은 불순도도 높다는 뜻이고, 엔트로피가 낮다는 것은 불순도도 낮다는 뜻입니다. 

엔트로피가 1이면 불순도가 최대, 0이면 불순도는 최소.




